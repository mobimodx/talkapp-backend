# GOOGLE CLOUD SPEECH-TO-TEXT V2 - STREAMING API

## TEMEL BÄ°LGÄ°LER
- **Protokol:** Sadece gRPC (REST deÄŸil)
- **KullanÄ±m:** GerÃ§ek zamanlÄ± ses transkripsiyon (mikrofon, canlÄ± ses)
- **Ä°ki yÃ¶nlÃ¼ stream:** Audio gÃ¶nderirsiniz â†’ SonuÃ§larÄ± gerÃ§ek zamanlÄ± alÄ±rsÄ±nÄ±z

## LÄ°MÄ°TLER
- **Chunk size:** Max 25 KB/request
- **Concurrent sessions:** 300/5 dakika
- **Requests:** 3,000/dakika

## REQUEST AKIÅI
1. **Ä°lk mesaj:** Config (recognizer + streaming_config) - audio yok
2. **Sonraki mesajlar:** Sadece audio bytes (max 25KB chunk'lar)

## PYTHON Ã–RNEK

```python
from google.cloud.speech_v2 import SpeechClient
from google.cloud.speech_v2.types import cloud_speech

client = SpeechClient()

# Config
recognition_config = cloud_speech.RecognitionConfig(
    auto_decoding_config=cloud_speech.AutoDetectDecodingConfig(),
    language_codes=["en-US"],  # veya ["auto"] otomatik dil algÄ±lama
    model="chirp_3"
)

streaming_config = cloud_speech.StreamingRecognitionConfig(
    config=recognition_config,
    streaming_features=cloud_speech.StreamingRecognitionFeatures(
        interim_results=True  # Ara sonuÃ§lar iÃ§in
    )
)

# Ä°lk request
config_request = cloud_speech.StreamingRecognizeRequest(
    recognizer=f"projects/{PROJECT_ID}/locations/global/recognizers/_",
    streaming_config=streaming_config
)

# Audio request'ler
def requests(config, audio_chunks):
    yield config
    for chunk in audio_chunks:
        yield cloud_speech.StreamingRecognizeRequest(audio=chunk)

# Stream
responses = client.streaming_recognize(requests=requests(config_request, audio_chunks))

# SonuÃ§lar
for response in responses:
    for result in response.results:
        print(result.alternatives[0].transcript)
        print(f"Final: {result.is_final}")
```

## NODE.JS Ã–RNEK

```javascript
const speech = require('@google-cloud/speech').v2;
const client = new speech.SpeechClient();

const configRequest = {
    recognizer: `projects/${PROJECT_ID}/locations/global/recognizers/_`,
    streamingConfig: {
        config: {
            autoDecodingConfig: {},
            languageCodes: ['en-US'],
            model: 'chirp_3'
        },
        streamingFeatures: {
            interimResults: true
        }
    }
};

// V2'de _streamingRecognize kullan
const stream = client._streamingRecognize()
    .on('data', (response) => {
        const result = response.results[0];
        console.log(result.alternatives[0].transcript);
    });

stream.write(configRequest);  // Ä°lk config
audioChunks.forEach(chunk => stream.write({ audio: chunk }));
stream.end();
```

## RESPONSE YAPISI

```javascript
{
    results: [{
        alternatives: [{
            transcript: "hello world",
            confidence: 0.98  // Sadece final'da
        }],
        is_final: true,      // true = kesin, false = ara sonuÃ§
        stability: 0.85,     // Sadece interim'de (0-1)
        language_code: "en-US"
    }]
}
```

## Ä°NTERÄ°M vs FINAL
- **Interim:** `is_final=false`, `stability` var, sÃ¼rekli gÃ¼ncellenir
- **Final:** `is_final=true`, `confidence` var, kesinleÅŸmiÅŸ sonuÃ§

## OTOMATÄ°K DÄ°L ALGILAMA (Chirp 3)
```python
language_codes=["auto"]  # Tam otomatik
# veya
language_codes=["en-US", "es-ES", "fr-FR"]  # Bu dillerden birini algÄ±la
```

## CHIRP 3 Ã–ZELLÄ°KLERÄ°
- âœ… Streaming Recognition
- âœ… Otomatik dil algÄ±lama
- âœ… Speaker diarization
- âœ… Otomatik noktalama
- âœ… Built-in denoiser
- âŒ Word timestamps (yok)
- âŒ Word confidence (yok)

## BEST PRACTICES
- 100ms chunk'lar gÃ¶nderin (16000Hz * 2 byte * 0.1s = 3.2KB gÃ¼venli)
- `autoDecodingConfig` kullanÄ±n
- 16000 Hz sample rate optimal
- Interim results iÃ§in `stability > 0.8` daha gÃ¼venilir

## HATALAR
- `INVALID_ARGUMENT`: Ä°lk mesajda audio gÃ¶nderme, config gÃ¶nder
- `RESOURCE_EXHAUSTED`: Quota aÅŸÄ±ldÄ±, concurrent stream azalt
- Chunk > 25KB: Chunk'larÄ± kÃ¼Ã§Ã¼lt

---

# BACKEND Ã–ZELLÄ°ÄÄ°: SESSÄ°ZLÄ°K ALGILAMA

## NASIL Ã‡ALIÅIR
Backend, Google'dan gelen sonuÃ§lara gÃ¶re otomatik sessizlik algÄ±lar:
- Her interim/final sonuÃ§ â†’ 2 saniye timer baÅŸlatÄ±r
- Yeni sonuÃ§ gelirse â†’ Timer sÄ±fÄ±rlanÄ±r
- 2 saniye hiÃ§ sonuÃ§ gelmezse â†’ `"silence"` event'i gÃ¶nderilir

## FRONTEND KULLANIMI

```javascript
ws.onmessage = (e) => {
  const data = JSON.parse(e.data);
  
  switch(data.type) {
    case 'interim':
      console.log('ğŸ¤ KonuÅŸuyor:', data.transcript);
      break;
      
    case 'final':
      console.log('âœ… CÃ¼mle bitti:', data.transcript);
      break;
      
    case 'silence':
      console.log('ğŸ¤« Sessizlik algÄ±landÄ±');
      // UI: "..." veya sessizlik ikonÄ± gÃ¶ster
      break;
  }
};
```

## EVENT TÄ°PLERÄ°

| Event | AÃ§Ä±klama |
|-------|----------|
| `connected` | WebSocket baÄŸlantÄ±sÄ± kuruldu |
| `interim` | Ara sonuÃ§ (konuÅŸma devam ediyor) |
| `final` | Kesin sonuÃ§ (cÃ¼mle tamamlandÄ±) |
| `silence` | 2 saniye sessizlik algÄ±landÄ± |
| `stopped` | Stream durduruldu |
| `error` | Hata oluÅŸtu |

## THRESHOLD AYARLAMA
VarsayÄ±lan: 2 saniye sessizlik
- Daha hassas â†’ 1.5 saniye
- Daha toleranslÄ± â†’ 3 saniye

Backend'de `streamingHandler.ts` dosyasÄ±ndaki `SILENCE_THRESHOLD_MS` deÄŸiÅŸtirilebilir.